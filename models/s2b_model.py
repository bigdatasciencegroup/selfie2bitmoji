import tensorflow as tf
from tensorpack import InputDesc, ModelDesc
from tensorpack.models.regularize import Dropout as tpDropout

from model_architectures import FACE_ENCODING_SIZE, BITMOJI_PARAM_SIZE, IMG_DIMS
import model_architectures as archs

class Selfie2BitmojiModel(ModelDesc):
    """
    The "e" network from the paper. Trained to emulate the Bitmoji rendering
    engine by producing images from parameters.
    """
    def __init__(self, args):
        """
        :param args: The cli arguments.
        """
        self.args = args

    def _get_inputs(self):
        """
        :return: The input descriptions for TensorPack.
        """
        return [InputDesc(tf.float32, (None,) + IMG_DIMS, 'Face_Images'),
                InputDesc(tf.float32, (None,) + IMG_DIMS, 'Bitmoji_Images')]


    def _build_graph(self, inputs):
        """
        Construct the graph and define self.cost.

        :param inputs: The input tensors fed in by TensorPack. A batch of real
                       face images.
        """
        face_images, bitmoji_images = inputs

        # Pipeline from face image to Bitmoji
        face_encodings = self._face_encoder(face_images)
        gen_faces = self._generator(face_encodings)
        params = self._param_encoder(gen_faces)
        avatar_synth_faces = self._avatar_synth(params)

        # GAN discriminator predictions
        d_preds_real = self._discriminator(bitmoji_images)
        d_preds_fake = self._discriminator(gen_faces)

        # Other misc results for losses
        gen_face_encodings = self.face_encoder(gen_faces)
        regen_bitmoji = self._generator(self._face_encoder(bitmoji_images))

        batch_size, height, width, channels = gen_faces.shape
        gen_faces_left_shift = tf.concat([gen_faces[:, :,1:,:],
                                          tf.zeros((batch_size, height, 1, channels))],
                                         axis=2)
        gen_faces_up_shift = tf.concat([gen_faces[:, 1:,:,:],
                                        tf.zeros((batch_size, 1, width, channels))],
                                       axis=1)

        ##
        # Losses:
        ##

        # L2 diff between first generated image and image generated by running
        # parameters through e. Enforces that G learns to generate images close
        # to those generated by e
        self.l_c = tf.reduce_mean(tf.square(gen_faces - avatar_synth_faces))

        # L2 loss between the embedding of the input image and the embedding of
        # the first generated image. Generator learns to maintain structural
        # information from the embedding.
        self.l_const = tf.reduce_mean(tf.square(face_encodings - gen_face_encodings))

        # Regular ol' gan loss. Enforces that generator generates in the style
        # of the target images
        self.l_gan_d = (tf.reduce_mean(tf.log(1 - d_preds_fake)) +
                        tf.reduce_mean(tf.log(d_preds_real)))
        self.l_gan_g = (tf.reduce_mean(tf.log(1 - d_preds_real)) +
                        tf.reduce_mean(tf.log(d_preds_fake)))

        # L2 loss between rendered Bitmoji images and those same images
        # regenerated (fed through the face encoder and generator). Encourages
        # the generator to be the identity function for Bitmoji images.
        self.l_tid = tf.reduce_mean(tf.square(bitmoji_images - regen_bitmoji))

        # Sum of the pixel-wise gradients
        self.l_tv = tf.reduce_mean(tf.sqrt(tf.square(gen_faces_left_shift - gen_faces) +
                                           tf.square(gen_faces_up_shift - gen_faces)))

        with tf.name_scope('Summaries'):
            pred_comp = tf.concat([face_images, gen_faces, avatar_synth_faces], axis=2)
            tf.summary.image('Preds', pred_comp)

            tf.summary.scalar('L_c', self.l_c)
            tf.summary.scalar('L_const', self.l_const)
            tf.summary.scalar('L_gan_d', self.l_gan_d)
            tf.summary.scalar('L_gan_g', self.l_gan_g)
            tf.summary.scalar('L_tid', self.l_tid)
            tf.summary.scalar('L_tv', self.l_tv)

    def _get_optimizer(self):
        self.lr = tf.Variable(self.args.lr_g, trainable=False, name='Avatar_Synth/LR')
        print(self.lr.name)
        return tf.train.AdamOptimizer(learning_rate=self.lr)



    ##
    # Models
    ##



    @staticmethod
    def _avatar_synth(params):
        """
        Constructs and computes the avatar synthesis model. This should be
        pretrained by run_avatar_synth.py and not trained in this complete
        model.

        :param params: The Bitmoji parameters to synthesize into Bitmoji images.

        :return: A batch of Bitmoji images synthesized from params.
        """
        def narrow_truncated_normal_initializer(shape, dtype=None, partition_info=None):
            initializer = tf.truncated_normal_initializer(stddev=0.05)
            return initializer(shape, dtype=dtype, partition_info=partition_info)

        with tf.variable_scope('Avatar_Synth'):
            arch = archs.avatar_synth_model

            # Reshape params into a 1x1 'image' for convolution
            preds = tf.reshape(params, (-1, 1, 1, BITMOJI_PARAM_SIZE))
            for i in xrange(len(arch['conv_filters']) - 1):
                # Apply ReLU and batch norm on all but the last layer
                activation = tf.nn.relu
                if i == len(arch['conv_filters']) - 2:
                    activation = tf.nn.tanh

                preds = tf.layers.conv2d_transpose(
                    preds,
                    arch['conv_filters'][i + 1],
                    arch['filter_widths'][i],
                    arch['strides'][i],
                    padding=arch['padding'][i],
                    activation=activation,
                    kernel_initializer=narrow_truncated_normal_initializer,
                    bias_initializer=tf.zeros_initializer,
                    name='Deconv_' + str(i),
                    reuse=tf.AUTO_REUSE,
                    trainable=False
                )

                if i < len(arch['conv_filters']) - 2:
                    preds = tf.layers.batch_normalization(preds,
                                                          name='BN_' + str(i),
                                                          reuse=tf.AUTO_REUSE)

        return preds
